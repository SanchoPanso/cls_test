{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bUq1-NnRccwd"
      },
      "source": [
        "# Download dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_CtHbsdcqSS"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/isaid_small_cropped'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGUOpEdMcsdi",
        "outputId": "eed5a3ef-2bea-444d-f672-a945571fdc86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7BZn8qucuik"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from urllib.parse import urlencode\n",
        "\n",
        "\n",
        "def download_yd_file(public_key: str, save_path: str):\n",
        "\n",
        "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "    final_url = base_url + urlencode(dict(public_key=public_key))\n",
        "    response = requests.get(final_url)\n",
        "    print(response.status_code)\n",
        "    download_url = response.json()['href']\n",
        "\n",
        "    download_response = requests.get(download_url)\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(download_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16seaRPjc2DF",
        "outputId": "276cae59-4ed0-423e-9929-12eccfbeafcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/isaid_small.zip\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "links = {\n",
        "    'isaid_small.zip': 'https://disk.yandex.ru/d/6KHSKFgIonskuA',#'https://disk.yandex.ru/d/qPlkJoQCwcZGow',\n",
        "}\n",
        "\n",
        "for filename in links.keys():\n",
        "    src_link = links[filename]\n",
        "    dst_path = os.path.join('/content', filename)\n",
        "    print(dst_path)\n",
        "    download_yd_file(src_link, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtGOP2pncb6z"
      },
      "outputs": [],
      "source": [
        "!unzip -q isaid_small.zip -d /content"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R7TguT9zV-h0"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KasEbaDIVpeW",
        "outputId": "df6bff98-9870-4a94-bcec-34055857f7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "Ultralytics YOLOv8.0.87 🚀 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=/content/isaid_small/data.yaml, epochs=10, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8s_seg_isaid_2504, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=25, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/segment/yolov8s_seg_isaid_25044\n",
            "Overriding model.yaml nc=80 with nc=15\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2776349  ultralytics.nn.modules.Segment               [15, 32, 128, [128, 256, 512]]\n",
            "YOLOv8s-seg summary: 261 layers, 11795901 parameters, 11795885 gradients, 42.7 GFLOPs\n",
            "\n",
            "Transferred 411/417 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/yolov8s_seg_isaid_25044', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/isaid_small/train/labels.cache... 1940 images, 552 backgrounds, 19 corrupt: 100% 1952/1952 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0001_13.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.9648]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_64.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_65.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_66.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_67.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_68.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_69.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_70.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_71.png: ignoring corrupt image/label: image size (6, 640) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0083_72.png: ignoring corrupt image/label: image size (6, 175) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0129_4.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0203      1.2094]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0141_10.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4719      1.3711]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0158_8.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9883      1.4516]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0169_8.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     7.3383]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0203_2.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7594]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0215_12.png: ignoring corrupt image/label: image size (640, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0215_18.png: ignoring corrupt image/label: image size (90, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0215_6.png: ignoring corrupt image/label: image size (640, 3) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/isaid_small/train/images/P0255_4.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4047]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/isaid_small/valid/labels.cache... 444 images, 128 backgrounds, 4 corrupt: 100% 448/448 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/isaid_small/valid/images/P0110_10.png: ignoring corrupt image/label: image size (640, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/isaid_small/valid/images/P0110_15.png: ignoring corrupt image/label: image size (640, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/isaid_small/valid/images/P0110_20.png: ignoring corrupt image/label: image size (150, 4) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/isaid_small/valid/images/P0110_5.png: ignoring corrupt image/label: image size (640, 4) <10 pixels\n",
            "Plotting labels to runs/segment/yolov8s_seg_isaid_25044/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/yolov8s_seg_isaid_25044\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      6.33G      1.678      2.415      2.725      1.126        206        640: 100% 242/242 [08:09<00:00,  2.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:22<00:00,  1.27it/s]\n",
            "                   all        444       7984       0.41     0.0706     0.0749     0.0477      0.408     0.0675     0.0723     0.0422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      6.29G      1.559      2.135      1.613      1.023        117        640: 100% 242/242 [08:35<00:00,  2.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:16<00:00,  1.65it/s]\n",
            "                   all        444       7984      0.422     0.0641     0.0745     0.0487      0.419     0.0618      0.071     0.0435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      4.14G      1.502      2.116      1.472      1.013         56        640: 100% 242/242 [08:26<00:00,  2.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:19<00:00,  1.44it/s]\n",
            "                   all        444       7984      0.223     0.0603     0.0607     0.0354      0.223     0.0584     0.0593     0.0317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      4.82G      1.489      2.083      1.382      1.009        205        640: 100% 242/242 [07:34<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:16<00:00,  1.67it/s]\n",
            "                   all        444       7984      0.296     0.0646     0.0627     0.0359      0.289     0.0639     0.0604     0.0313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      7.14G      1.501      2.108      1.339      1.006        300        640: 100% 242/242 [08:05<00:00,  2.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:21<00:00,  1.32it/s]\n",
            "                   all        444       7984      0.299     0.0629     0.0589     0.0319      0.294      0.057     0.0526     0.0246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10         6G      1.481      2.052      1.269      1.001         46        640: 100% 242/242 [08:14<00:00,  2.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:18<00:00,  1.55it/s]\n",
            "                   all        444       7984      0.439     0.0662     0.0696     0.0415      0.435      0.065     0.0662      0.033\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      6.61G      1.439      1.975      1.208      0.992        175        640: 100% 242/242 [08:16<00:00,  2.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:13<00:00,  2.00it/s]\n",
            "                   all        444       7984      0.151     0.0741      0.069     0.0397      0.149     0.0715     0.0645     0.0326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      4.81G      1.416      1.959      1.136     0.9828        134        640: 100% 242/242 [08:15<00:00,  2.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 28/28 [00:18<00:00,  1.56it/s]\n",
            "                   all        444       7984      0.158     0.0672     0.0713     0.0424      0.156      0.063      0.066     0.0344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      3.83G      1.396      1.935      1.107     0.9646        218        640:   9% 22/242 [00:44<07:21,  2.01s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1178, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/data/build.py\", line 39, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.9/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.9/threading.py\", line 316, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 391, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 370, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 191, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 306, in _do_train\n",
            "    for i, batch in pbar:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1193, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1299, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1492, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 347, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 340, in fp_write\n",
            "    fp.write(str(s))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/utils.py\", line 127, in inner\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/redirect.py\", line 640, in write\n",
            "    self._old_write(data)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1178, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/data/build.py\", line 39, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.9/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.9/threading.py\", line 316, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 391, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 370, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 191, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 306, in _do_train\n",
            "    for i, batch in pbar:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1193, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1299, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1492, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 347, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 340, in fp_write\n",
            "    fp.write(str(s))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/utils.py\", line 127, in inner\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/redirect.py\", line 640, in write\n",
            "    self._old_write(data)\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg0 █▅▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg1 ▁▅█▇▇▅▄▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg2 ▁▅█▇▇▅▄▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50(B) ██▂▃▁▆▅▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50(M) ██▃▄▁▆▅▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  metrics/mAP50-95(B) ██▂▃▁▅▄▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  metrics/mAP50-95(M) ██▄▃▁▄▄▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/precision(B) ▇█▃▅▅█▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/precision(M) ▇█▃▄▅█▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/recall(B) ▆▃▁▃▂▄█▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/recall(M) ▆▃▂▄▁▅█▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         model/GFLOPs ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     model/parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      model/speed(ms) ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▃▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/dfl_loss █▃▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/seg_loss █▄▃▃▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▇▄█▅▆▅▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▂▃▆▄▃█▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/dfl_loss █▃█▅▅▄▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/seg_loss ▆▄█▃█▅▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg0 0.00406\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg1 0.00406\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr/pg2 0.00406\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50(B) 0.07131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50(M) 0.06604\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  metrics/mAP50-95(B) 0.04242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  metrics/mAP50-95(M) 0.03437\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/precision(B) 0.15819\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/precision(M) 0.15585\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/recall(B) 0.06717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/recall(M) 0.06303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         model/GFLOPs 42.721\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     model/parameters 11795901\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      model/speed(ms) 25.269\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 1.41613\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 1.1361\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/dfl_loss 0.98279\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/seg_loss 1.95865\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 1.4776\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 2.54809\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/dfl_loss 0.98363\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/seg_loss 1.41131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/wandb/offline-run-20230425_145013-sbuyz25n\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230425_145013-sbuyz25n/logs\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "\n",
        "import os\n",
        "\n",
        "model = 'yolov8s-seg.pt'\n",
        "\n",
        "epochs = 10\n",
        "imgsz = 640\n",
        "batch = 8\n",
        "warmup = 3\n",
        "half = True\n",
        "lr0 = 0.01\n",
        "\n",
        "copy_paste = 0.1\n",
        "mixup = 0.1\n",
        "degrees = 25\n",
        "flipud = 0.5\n",
        "\n",
        "\n",
        "name = 'yolov8s_seg_isaid_2504'\n",
        "data = os.path.join(dataset_dir, 'data.yaml')\n",
        "\n",
        "!yolo segment train \\\n",
        "    data={data} \\\n",
        "    model={model} \\\n",
        "    epochs={epochs} \\\n",
        "    imgsz={imgsz} \\\n",
        "    batch={batch} \\\n",
        "    warmup_epochs={warmup} \\\n",
        "    half={half} \\\n",
        "    lr0={lr0} \\\n",
        "    copy_paste={copy_paste} \\\n",
        "    mixup={mixup} \\\n",
        "    degrees={degrees} \\\n",
        "    flipud={flipud} \\\n",
        "    name={name}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a-LUPFiIvTsE"
      },
      "source": [
        "# Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtRpumOO0A8V",
        "outputId": "749904cb-c8db-49d4-c64e-843983e2c23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.87 🚀 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11785405 parameters, 0 gradients, 42.5 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 40.2MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/isaid_small/valid/labels... 45 images, 0 backgrounds, 0 corrupt: 100% 45/45 [00:01<00:00, 23.12it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/isaid_small/valid/labels.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:22<00:00,  7.51s/it]\n",
            "                   all         45       7984      0.593     0.0688     0.0488     0.0322      0.587     0.0675     0.0489     0.0306\n",
            "          storage_tank         45          1          1          0          0          0          1          0          0          0\n",
            "         Large_Vehicle         45        609      0.334      0.374       0.27      0.116      0.311      0.353      0.249      0.107\n",
            "         Small_Vehicle         45       6225       0.48     0.0161     0.0753     0.0307      0.492     0.0168     0.0958     0.0411\n",
            "                  ship         45        329    0.00279    0.00608    0.00225    0.00114    0.00415    0.00912    0.00336    0.00133\n",
            "                Harbor         45         91          1          0          0          0          1          0          0          0\n",
            "      baseball_diamond         45         21          1          0          0          0          1          0          0          0\n",
            "    Ground_Track_Field         45          5          1          0          0          0          1          0          0          0\n",
            "     Soccer_ball_field         45         12     0.0159      0.167      0.006    0.00142     0.0157      0.167      0.006     0.0021\n",
            "         Swimming_pool         45        235          0          0          0          0          0          0          0          0\n",
            "            Roundabout         45          5      0.474        0.4      0.322      0.297        0.4        0.4      0.322      0.275\n",
            "          tennis_court         45        137          1          0          0          0          1          0          0          0\n",
            "      basketball_court         45          7          1          0          0          0          1          0          0          0\n",
            "                 plane         45        296          1          0    0.00704    0.00493          1          0    0.00704    0.00141\n",
            "            Helicopter         45         11          0          0          0          0          0          0          0          0\n",
            "Speed: 8.1ms preprocess, 31.4ms inference, 0.0ms loss, 63.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/yolov8sseg_isaid\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Write your model path\n",
        "model = '/content/drive/MyDrive/runs/segment/yolov8sseg_isaid3/weights/best.pt'\n",
        "\n",
        "name = 'yolov8sseg_isaid'\n",
        "data = os.path.join(dataset_dir, 'data.yaml')\n",
        "\n",
        "!yolo segment val model={model} name={name} data={data}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pueD_yp9vXyW"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "pxYOJ440gx4q",
        "outputId": "294d8036-e925-478f-aa8c-7f6a3532b761"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230501_134957-rbac50h9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9' target=\"_blank\">confused-dream-13</a></strong> to <a href='https://wandb.ai/proektbl-1960/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/proektbl-1960/YOLOv8' target=\"_blank\">https://wandb.ai/proektbl-1960/YOLOv8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9' target=\"_blank\">https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f1921d37280>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "import wandb\n",
        "\n",
        "wandb.init(project='YOLOv8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ST_GANFh9um",
        "outputId": "e6c2bf20-1d9f-4720-e76f-16f49b186f64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 19 Large_Vehicles, 22.8ms\n",
            "Speed: 1.9ms preprocess, 22.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x512 3 Large_Vehicles, 5 Small_Vehicles, 22.1ms\n",
            "Speed: 1.7ms preprocess, 22.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 Large_Vehicles, 3 Small_Vehicles, 2 Harbors, 14.9ms\n",
            "Speed: 1.4ms preprocess, 14.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 512x640 6 Large_Vehicles, 6 Small_Vehicles, 17.6ms\n",
            "Speed: 4.4ms preprocess, 17.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 36 Large_Vehicles, 4 Small_Vehicles, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 5 Small_Vehicles, 14.6ms\n",
            "Speed: 1.7ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 29 Large_Vehicles, 6 Small_Vehicles, 21.9ms\n",
            "Speed: 2.0ms preprocess, 21.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 2 Small_Vehicles, 12.7ms\n",
            "Speed: 1.0ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 192x640 (no detections), 12.5ms\n",
            "Speed: 0.9ms preprocess, 12.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 Large_Vehicles, 1 Small_Vehicle, 1 baseball_diamond, 21.9ms\n",
            "Speed: 2.7ms preprocess, 21.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = '/content/drive/MyDrive/runs/segment/yolov8s_seg_isaid_25044/weights/best.pt'\n",
        "model = YOLO(model)\n",
        "\n",
        "valid_images_dir = os.path.join(dataset_dir, 'valid', 'images')\n",
        "valid_image_files = os.listdir(valid_images_dir)\n",
        "valid_image_files.sort()\n",
        "valid_image_files = valid_image_files[:10]\n",
        "\n",
        "for f in valid_image_files:\n",
        "    img = cv2.imread(os.path.join(valid_images_dir, f))\n",
        "    res = model(img)\n",
        "    res_plotted = res[0].plot()\n",
        "    #cv2_imshow(res_plotted)\n",
        "\n",
        "    #res_plotted = Image.fromarray(res_plotted)\n",
        "    wandb.log({f'{f} ': wandb.Image(res_plotted)})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "9e22c819f0774ebe9e577bd6b705b56e",
            "12968f70a743457eb8f66364163e03b2",
            "03de17e6fc434353bf93011ea19bc94e",
            "f00a64cfcf66450bb32a0216d70ffedf",
            "57ccca119c5545599af492ead351d019",
            "a9d5ad80414549a68a8a3ec5fab9b0c9",
            "1de9f6cd43324c4497f0d7394ffee981",
            "9ddd0286fddf4ad98b7eb6775f7ae08d"
          ]
        },
        "id": "fdPIt8uakWDE",
        "outputId": "4c27f7d9-dc5c-4142-b680-a4d006948941"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e22c819f0774ebe9e577bd6b705b56e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='17.155 MB of 17.155 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">confused-dream-13</strong> at: <a href='https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9' target=\"_blank\">https://wandb.ai/proektbl-1960/YOLOv8/runs/rbac50h9</a><br/>Synced 5 W&B file(s), 60 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230501_134957-rbac50h9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "o94Y3Vh9do4-",
        "bUq1-NnRccwd",
        "a-LUPFiIvTsE"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03de17e6fc434353bf93011ea19bc94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de9f6cd43324c4497f0d7394ffee981",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ddd0286fddf4ad98b7eb6775f7ae08d",
            "value": 0.9987676564651534
          }
        },
        "12968f70a743457eb8f66364163e03b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ccca119c5545599af492ead351d019",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d5ad80414549a68a8a3ec5fab9b0c9",
            "value": "17.155 MB of 17.176 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1de9f6cd43324c4497f0d7394ffee981": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ccca119c5545599af492ead351d019": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ddd0286fddf4ad98b7eb6775f7ae08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e22c819f0774ebe9e577bd6b705b56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12968f70a743457eb8f66364163e03b2",
              "IPY_MODEL_03de17e6fc434353bf93011ea19bc94e"
            ],
            "layout": "IPY_MODEL_f00a64cfcf66450bb32a0216d70ffedf"
          }
        },
        "a9d5ad80414549a68a8a3ec5fab9b0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f00a64cfcf66450bb32a0216d70ffedf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
