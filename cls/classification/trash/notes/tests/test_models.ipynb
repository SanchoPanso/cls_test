{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import sys\n",
    "sys.path.append(\"/home/timssh/ML/TAGGING/CLS/classification\")\n",
    "from os.path import join\n",
    "from scripts.utils import parse_meta, get_meta_id\n",
    "from train.model import InferDataset\n",
    "from train.augmentation import PreProcess, DataAugmentation\n",
    "\n",
    "Aug = DataAugmentation().eval()\n",
    "Pre = PreProcess(gray=False, vflip=False, arch=\"eff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = ['hair_color']\n",
    "PATH2TEST = '/home/timssh/ML/TAGGING/test'\n",
    "\n",
    "old_train = {\n",
    "    \"models\": {\n",
    "        # \"body_type\": \"/home/timssh/ML/TAGGING/source_old/wandb/body_type/version_0_train_eff_44_0.01/checkpoints/epoch=52-step=3604.pt\",\n",
    "        # \"tits_size\": \"/home/timssh/ML/TAGGING/source_old/wandb/tits_size/version_0_train_eff_32_0.01/checkpoints/epoch=90-step=11193.pt\",\n",
    "        # \"sex_positions\": \"/home/timssh/ML/TAGGING/source_old/wandb/sex_positions/version_0_train_eff_44_0.01/checkpoints/epoch=47-step=18384.pt\",\n",
    "        \"hair_color\": \"/home/timssh/ML/TAGGING/source_old/wandb/hair_color/version_5_train_eff_44_0.01/checkpoints/epoch=50-step=4386.pt\",\n",
    "        # \"hair_type\": \"/home/timssh/ML/TAGGING/source_old/wandb/hair_type/version_1_val_eff_44_0.01/checkpoints/epoch=76-step=2156.pt\",\n",
    "    },\n",
    "    \"source\": \"/home/timssh/ML/TAGGING/source_old\",\n",
    "}\n",
    "valid_train = {\n",
    "    \"models\": {\n",
    "        # \"sex_positions\": \"/home/timssh/ML/TAGGING/source_valid/wandb/sex_positions/version_0_train_eff_32_0.001/checkpoints/epoch=69-step=119560.pt\",\n",
    "        # \"hair_type\": \"/home/timssh/ML/TAGGING/source_valid/wandb/hair_type/version_0_train_eff_32_0.001/checkpoints/epoch=138-step=137332.pt\"\n",
    "        # \"tits_size\": \"/home/timssh/ML/TAGGING/source_valid/wandb/tits_size/version_1_train_eff_36_0.01/checkpoints/epoch=65-step=71016.pt\",\n",
    "        \"hair_color\": \"/home/timssh/ML/TAGGING/source_valid/wandb/hair_color/version_0_train_eff_32_0.001/checkpoints/epoch=121-step=170068.pt\",\n",
    "    },\n",
    "    \"source\": \"/home/timssh/ML/TAGGING/source_valid\",\n",
    "}\n",
    "path_meta = '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tits_size\n",
      "/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493\n",
      "tits_size\n",
      "/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493\n"
     ]
    }
   ],
   "source": [
    "# GROUPS = old_train['models'].keys()\n",
    "GROUPS = [\"tits_size\"]\n",
    "\n",
    "\n",
    "if path_meta:\n",
    "    meta_real = {path_meta : get_meta_id(path_meta + '/meta.json')}\n",
    "\n",
    "meta_old = parse_meta(old_train['models'], InferDataset, Aug, Pre, old_train['source'], GROUPS, PATH2TEST)\n",
    "meta_valid = parse_meta(valid_train['models'], InferDataset, Aug, Pre, valid_train['source'], GROUPS, PATH2TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(meta_1, meta_2):\n",
    "    diff_list = []\n",
    "    for picset in meta_1.keys():\n",
    "        for id in meta_1[picset]:\n",
    "            train_1 = meta_1[picset][id]['trained']\n",
    "            train_2 = meta_2[picset][id]['trained']\n",
    "            for group_ in GROUP:\n",
    "                item_1 = list(filter(lambda x: x['group'] == group_, train_1))\n",
    "                if len(item_1) > 1:\n",
    "                    item_1 = [item_1[-1]]\n",
    "                elif len(item_1) == 0:\n",
    "                    item_1.append({'group': group_, 'category': []})\n",
    "                item_2 = list(filter(lambda x: x['group'] == group_, train_2))\n",
    "                if len(item_2) > 1:\n",
    "                    item_2 = [item_2[-1]]\n",
    "                elif len(item_2) == 0:\n",
    "                    item_2.append({'group': group_, 'category': []})\n",
    "                if item_1 != item_2:\n",
    "                    diff_list.append({'path': join(picset,'picture', meta_2[picset][id]['origin']['filename']), 'model_1': item_1, 'model_2': item_2})\n",
    "    return diff_list\n",
    "\n",
    "def show_res(path, model_1, model_2):\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    img = Image.open(path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print('model_1', model_1)\n",
    "    print('model_2', model_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/07db4ae7aa093215ad231c959c553bb2.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['black hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['brown hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/129380a67b5e5d6e923dca5f06eacf4f.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['brown hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['black hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/b29c9401132ccb64e33dd45f821a7ced.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['black hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['brown hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/d696e01626b240042bea1ef44ab51b59.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['brown hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['red hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/5e47d7e1f4de6bbe99af96b94bc29f78.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['brown hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['black hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/ac5b6b024269574c4831b9ca58926d39.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['black hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['brown hair']}]},\n",
       " {'path': '/home/timssh/ML/TAGGING/test/tits_size/1/mofos-solo-porn-493/picture/695454a072e99fc1907c353bf4a8b2fe.jpeg',\n",
       "  'model_1': [{'group': 'hair_color', 'category': ['black hair']}],\n",
       "  'model_2': [{'group': 'hair_color', 'category': ['brown hair']}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = find_diff(meta_valid, meta_old)\n",
    "print(len(ret))\n",
    "it = iter(ret)\n",
    "ret[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer: Model 2: ['brown hair']\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import Button, HBox, Text\n",
    "from IPython.display import Image\n",
    "\n",
    "data = ret\n",
    "list_of_buttons = []\n",
    "\n",
    "def display_image(image_path):\n",
    "    display(Image(filename=image_path))\n",
    "\n",
    "def on_button_click(b):\n",
    "    global current_index\n",
    "    clear_output()\n",
    "    print(f\"Correct answer: {b.description}\")\n",
    "    current_index += 1\n",
    "    if current_index < len(data):\n",
    "        display_next_image()\n",
    "\n",
    "def item_and_click(item):\n",
    "    def on_button_click(b):\n",
    "        list_of_buttons.append((b.description, item['path']))\n",
    "        global current_index\n",
    "        clear_output()\n",
    "        print(f\"Correct answer: {b.description}\")\n",
    "        current_index += 1\n",
    "        if current_index < len(data):\n",
    "            display_next_image()\n",
    "    return on_button_click\n",
    "\n",
    "def on_custom_button_click(b):\n",
    "    global current_index\n",
    "    clear_output()\n",
    "    print(f\"Correct answer: {custom_text.value}\")\n",
    "    current_index += 1\n",
    "    if current_index < len(data):\n",
    "        display_next_image()\n",
    "\n",
    "def text_and_click(item, custom_text):\n",
    "    def on_custom_button_click(b):\n",
    "        global current_index\n",
    "        clear_output()\n",
    "        list_of_buttons.append((\"Custom: \" + custom_text.value, item['path']))\n",
    "        print(f\"Correct answer: {custom_text.value}\")\n",
    "        current_index += 1\n",
    "        if current_index < len(data):\n",
    "            display_next_image()\n",
    "    return on_custom_button_click\n",
    "\n",
    "def display_next_image():\n",
    "    global current_index\n",
    "    item = data[current_index]\n",
    "    display_image(item['path'])\n",
    "    \n",
    "    model_1_output = item['model_1'][0]['category']\n",
    "    model_2_output = item['model_2'][0]['category']\n",
    "    \n",
    "    model_1_button = Button(description=f\"Model 1: {model_1_output}\")\n",
    "    model_2_button = Button(description=f\"Model 2: {model_2_output}\")\n",
    "    \n",
    "    # model_1_button.on_click(on_button_click)\n",
    "    # model_2_button.on_click(on_button_click)\n",
    "    model_1_button.on_click(item_and_click(item))\n",
    "    model_2_button.on_click(item_and_click(item))\n",
    "    \n",
    "    custom_text = Text(value=\"\")\n",
    "    custom_button = Button(description=\"Custom\")\n",
    "    \n",
    "    custom_button.on_click(on_custom_button_click)\n",
    "    custom_button.on_click(text_and_click(item, custom_text))\n",
    "    \n",
    "    # display(HBox([model_1_button, model_2_button, custom_text, custom_button]))\n",
    "    display(HBox([model_1_button, model_2_button, custom_button]))\n",
    "\n",
    "current_index = 0\n",
    "display_next_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: 30 \n",
      " model_2: 36 \n",
      " custom: 0\n"
     ]
    }
   ],
   "source": [
    "model_1_count = 0\n",
    "model_2_count = 0\n",
    "custom_count = 0\n",
    "for item in list_of_buttons:\n",
    "    if item[0][:7] == \"Model 1\":\n",
    "        model_1_count += 1\n",
    "    elif item[0][:7] == \"Model 2\":\n",
    "        model_2_count += 1\n",
    "    else:\n",
    "        custom_count += 1\n",
    "\n",
    "print('model_1:', model_1_count, '\\n', 'model_2:', model_2_count, '\\n', 'custom:', custom_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# define the source directory and destination directory\n",
    "dst_dir = \"/home/timssh/ML/TAGGING/tested_bad/\" + GROUP[0]\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "# get the list of file paths\n",
    "# iterate over the file paths and copy each file to the destination directory\n",
    "for file_path in list_of_buttons:\n",
    "    if 'Model 1' not in file_path[0]:\n",
    "        shutil.copy(file_path[1], dst_dir + '/' + file_path[1].split('/')[-1])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
